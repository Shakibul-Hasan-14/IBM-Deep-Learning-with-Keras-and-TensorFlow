{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sys.setrecursionlimit function is used to increase the recursion limit, which helps prevent potential recursion errors when running complex models with deep nested functions or when using certain libraries like TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Increase recursion limit to prevent potential issues\n",
    "sys.setrecursionlimit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Suppress all Python warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set TensorFlow log level to suppress warnings and info messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = all logs, 1 = filter out INFO, 2 = filter out INFO and WARNING, 3 = ERROR only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Validation data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "x_train, x_val = x_train / 255.0, x_val / 255.0\n",
    "\n",
    "print(f'Training data shape: {x_train.shape}')\n",
    "print(f'Validation data shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Model with Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure Hyperparameter Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "# Create a RandomSearch Tuner \n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "# Display a summary of the search space \n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Hyperparameter Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 05s]\n",
      "val_accuracy: 0.969650000333786\n",
      "\n",
      "Best val_accuracy So Far: 0.9801499843597412\n",
      "Total elapsed time: 00h 08m 34s\n",
      "Results summary\n",
      "Results in my_dir\\intro_to_kt\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units: 416\n",
      "learning_rate: 0.0009124105694925094\n",
      "Score: 0.9801499843597412\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "learning_rate: 0.00178701749121327\n",
      "Score: 0.9783500134944916\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "learning_rate: 0.00034109005522774783\n",
      "Score: 0.9780499935150146\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.0032285872305509375\n",
      "Score: 0.9760000109672546\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.005548950103091091\n",
      "Score: 0.972350001335144\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "learning_rate: 0.0003492037347843834\n",
      "Score: 0.9720499813556671\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.005440954850111082\n",
      "Score: 0.969650000333786\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.0001079063777579721\n",
      "Score: 0.9658499956130981\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "learning_rate: 0.00010234591515410909\n",
      "Score: 0.93995001912117\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "learning_rate: 0.00015747546128422012\n",
      "Score: 0.9377000033855438\n"
     ]
    }
   ],
   "source": [
    "# Run the hyperparameter search \n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val)) \n",
    "\n",
    "# Display a summary of the results \n",
    "tuner.results_summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze and Use Best Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "The optimal number of units in the first dense layer is 416. \n",
      "The optimal learning rate for the optimizer is 0.0009124105694925094. \n",
      "\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2376 - accuracy: 0.9311 - val_loss: 0.1170 - val_accuracy: 0.9653\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0950 - accuracy: 0.9714 - val_loss: 0.0973 - val_accuracy: 0.9688\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0606 - accuracy: 0.9817 - val_loss: 0.0884 - val_accuracy: 0.9742\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.0837 - val_accuracy: 0.9749\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.0833 - val_accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0887 - val_accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0920 - val_accuracy: 0.9766\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0858 - val_accuracy: 0.9787\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.1048 - val_accuracy: 0.9758\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9766\n",
      "Test accuracy: 0.9765999913215637\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters \n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] \n",
    "print(f\"\"\" \n",
    "The optimal number of units in the first dense layer is {best_hps.get('units')}. \n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}. \n",
    "\"\"\") \n",
    "\n",
    "# Build and Train the Model with Best Hyperparameters \n",
    "model = tuner.hypermodel.build(best_hps) \n",
    "model.fit(x_train, y_train, epochs=10, validation_split=0.2) \n",
    "\n",
    "# Evaluate the model on the test set \n",
    "test_loss, test_acc = model.evaluate(x_val, y_val) \n",
    "print(f'Test accuracy: {test_acc}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Keras Tuner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Validation data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the MNIST data set \n",
    "(x_train, y_train), (x_val, y_val) = mnist.load_data() \n",
    "x_train, x_val = x_train / 255.0, x_val / 255.0 \n",
    "\n",
    "# Print the shapes of the training and validation datasets\n",
    "print(f'Training data shape: {x_train.shape}') \n",
    "print(f'Validation data shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Model with Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model-building function\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure Hyperparameter Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\intro_to_kt\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "# Create a RandomSearch Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,  # Ensure 'build_model' function is defined from previous code\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "# Display a summary of the search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Hyperparameter Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\intro_to_kt\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units: 416\n",
      "learning_rate: 0.0009124105694925094\n",
      "Score: 0.9801499843597412\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "learning_rate: 0.00178701749121327\n",
      "Score: 0.9783500134944916\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "learning_rate: 0.00034109005522774783\n",
      "Score: 0.9780499935150146\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.0032285872305509375\n",
      "Score: 0.9760000109672546\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.005548950103091091\n",
      "Score: 0.972350001335144\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "learning_rate: 0.0003492037347843834\n",
      "Score: 0.9720499813556671\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.005440954850111082\n",
      "Score: 0.969650000333786\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.0001079063777579721\n",
      "Score: 0.9658499956130981\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "learning_rate: 0.00010234591515410909\n",
      "Score: 0.93995001912117\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "learning_rate: 0.00015747546128422012\n",
      "Score: 0.9377000033855438\n"
     ]
    }
   ],
   "source": [
    "# Run the hyperparameter search \n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val)) \n",
    "\n",
    " # Display a summary of the results \n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze and Use Best Hyperparameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "The optimal number of units in the first dense layer is 416. \n",
      "The optimal learning rate for the optimizer is 0.0009124105694925094. \n",
      "\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2376 - accuracy: 0.9307 - val_loss: 0.1347 - val_accuracy: 0.9603\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0960 - accuracy: 0.9710 - val_loss: 0.1106 - val_accuracy: 0.9647\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0627 - accuracy: 0.9808 - val_loss: 0.0859 - val_accuracy: 0.9735\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0420 - accuracy: 0.9871 - val_loss: 0.0831 - val_accuracy: 0.9762\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.0780 - val_accuracy: 0.9765\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0886 - val_accuracy: 0.9777\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0745 - val_accuracy: 0.9805\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0948 - val_accuracy: 0.9758\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1129 - val_accuracy: 0.9741\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9761\n",
      "Validation accuracy: 0.9761000275611877\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters \n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] \n",
    "print(f\"\"\" \n",
    "The optimal number of units in the first dense layer is {best_hps.get('units')}. \n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}. \n",
    "\"\"\") \n",
    "\n",
    "# Build and train the model with best hyperparameters \n",
    "model = tuner.hypermodel.build(best_hps) \n",
    "model.fit(x_train, y_train, epochs=10, validation_split=0.2) \n",
    "\n",
    "# Evaluate the model on the validation set \n",
    "val_loss, val_acc = model.evaluate(x_val, y_val) \n",
    "print(f'Validation accuracy: {val_acc}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "prev_pub_hash": "bcaac19a1acad1c392f0e26848b84e2be7a94464a9796c911499271eb3d0672a"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
